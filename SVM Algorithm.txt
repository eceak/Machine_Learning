import numpy as np
import math
import pandas as pd
import matplotLib.pyplot as plt
from sklearn import svm

#veri seti tanimlandi
data1=pd.read_csv("/home/ece/Belgeler/svm.csv")
data1

# Y egitim setinden , X egitim seti ayriliyor
X1=data1[ ‘x1']
X2=data1[‘x2']
X_training=np.array( List(zip(X1,X2)))
X_training

y_training=data1[ "y"]
y_training

target_names=['-1', ‘+1']
target_names

#2 ye ayrilan veri seti cizildi

idxPLus=y_training[y_training<0].index
idxMin=y_trainingly_training>0].index
plt.scatter(X_training[idxPlus,0],X_training[idxPLlus,1],c='purple',s=50)
plt.scatter(X_training[idxMin,0] ,X_training[idxMin,1],c='pink',s=50)
plt. Legend(target_names, loc=2)

plt.xlabel( 'X1")

plt.ylabel( 'X2"):

plt.show( ‘svm.png')

#egitim verilerini egitmek icin lineer kernel kullanilarak fit() islevi yapildi
svc = svm.SVC(kernel='linear').fit(X_training,y_training)
svc

svc.get_params(True)

#egitilen model icin cizilecek gorselin sinirlari belirlendi
lbX1=math.floor(min(X_training[: ,0]))-1
lbX1=math.ceil(max(X_training[: ,0]))+1
lbX2=math.floor(min(X_training[:,1]))-1
lbX2=math.ceil(max(X_training[:,1]))+1
[lbX1,lbX1,lbX2,lbX2]

idxPLus=y_training[y_training<0].index
idxMin=y_training[y_training>0].index
plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='purple',s=50)
plt.scatter(X_training[idxMin, 0],X_training[idxMin,1],c="green',s=50)
plt. legend(target_names, Loc=2)

X,Y = np.mgrid[lbX1:lbX1:100j, lbX2:lbX2:100j]

Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])

Z = Z.reshape(X.shape)

plt.contourf(X,Y,Z > 0,alpha=0.4)
plt.contour(X,¥,Z,colors=['red'], linestyles=[ '-- '],levels=[0])

plt.title( "Dogrusal olarak ayrilabilir'’)
plt.show( "svm1.png')

#margin ve destek vektoru belirtildi
idxPLus=y_training[y_training<0].index
idxMin=y_training[y_training>0].index
plt.scatter(X_training[idxPLus ,0],X_training[idxPlus,1],c='b',s=50)
plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)
plt.legend(target_names, loc=2)
X,Y = np.mgrid[lbX1:lbX1:100j), lbX2:lbX2:100j]
Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])
Z = Z.reshape(X.shape)
plt.contourf(X,Y,Z > 0,alpha=0.4)
pLt.contour(X,Y,Z,colors=[ 'k','k','k'], Linestyles=['--', '-", '--'],levels=[-1,0,1])
plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1],s=120,facecolors='none')
pLt.scatter(X_training[: ,0],X_training[: ,1],c=y_training,s=50,alpha=0.95);
plt.title( ‘Margin and Support Vectors')
plt.show( 'svm2.png')

#SVM kullanilarak egitim verileri ile tahmin yapildi
svc. .predict([[3,6]])
dxPlus=y_training[y_training<0]. index
idxMin=y_training[y_training>0]. index
plt.scatter(X_training[idxPlus ,0],X_training[idxPlus,1],c='b',s=50)
plt.scatter(X_training[idxMin,0] ,X training[idxMin,1],c='r',s=50)
plt.scatter(3,6,c='r',marker='s',s=90)
plt.legend(['-i', '+1', 'tahmin'], loc=2)

X,Y = np.mgrid[lbX1:lbX1: 100j, lbX2:ubX2:100j]
Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])
Z= Z.reshape(X.shape)
plt.contourf(X,Y,Z > 0,alpha=0. 4)
plt.contour(X,Y,Z,colors=['k'], Linestyles=[ '-'], levels=[0])

plt.title( "Tahmin')
plt.show( ‘svm3.png")

